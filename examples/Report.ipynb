{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Project Report: bci4als\n",
    "#### Authors: Evyatar Luvaton, Noam Siegel\n",
    "\n",
    "This software was developed for the course Brain-Computer-Interface for ALS Patients, December 2020.\n",
    "\n",
    "Over the mid-semester project we have integrated the different parts of BCI which been discussed in the course.\n",
    "We introduce bci4als, a complete pipeline for EEG motor imagery data recording and classification.\n",
    "\n",
    "\n",
    "The pipeline is general, so it can be extended to other BCI settings like P300, SSVEP.\n",
    "\n",
    "The first part of this report presents the python package bci4als.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "First, go ahead and install bci4als (if you haven't already done so).\n",
    "\n",
    "```{python}\n",
    "pip install -i https://test.pypi.org/simple/ bci4als;\n",
    "```\n",
    "\n",
    "The main codebase lies in the `bci4als.mi` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bci4als.mi.test_model'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-5f04ac2b3943>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmne\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpickle\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mbci4als\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmi\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmi\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\lenovo\\pycharmprojects\\bci-4-als\\src\\bci4als\\mi\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mextract_features\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mextract_features\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0massess_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mtest_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtest_model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'bci4als.mi.test_model'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import pickle\n",
    "import bci4als.mi as mi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - End-to-End Walkthrough\n",
    "\n",
    "We will now guide you how to use the `bci4als` pipeline from end to end.\n",
    "\n",
    "<B>Note:</B>\n",
    "All the scripts share common configuration parameters, which are stored in a multi-level `dict` object called `mi.params`. The first-layer keys indicate the category of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "params = mi.params\n",
    "params.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to see the parameters related to preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_params = params['preprocess']\n",
    "print('\\n'.join('{}: {}'.format(k, v) for k, v in preprocess_params.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### step 1 - record experiment\n",
    "the `bci4als.mi.record` module is responsible for executing a motor imagery experiment and recording the stimulus.\n",
    "\n",
    "the `bci4als.mi.record.start()` function starts an interactive gui which will guide you through executing a mi experiment. it assumes you:\n",
    "\n",
    "1) have an external application streaming eeg data (via lsl) to lab recorder.\n",
    "\n",
    "2) have a `currentstudy` directory into which the collected data will be saved.\n",
    "\n",
    "3) opened `labrecorder`.\n",
    "\n",
    "once you are ready, begin recording:\n",
    "\n",
    "```{python}\n",
    "mi.record.start()\n",
    "```\n",
    "\n",
    "Now follow the following steps:\n",
    "\n",
    "1) You should see a \"Welcome\" messagebox. Press \"OK\" to continue.\n",
    "\n",
    "2) Select the CurrentStudy folder.\n",
    "\n",
    "3) Type a new Session ID (this will be the name of the folder). Press \"OK\" to continue.\n",
    "\n",
    "4) You should a confirmation messagebox. Press \"OK\" to continue.\n",
    "\n",
    "5) Point the LabRecorder to the folder created at step 3. Set the name of the file EEG.xdf\n",
    "\n",
    "6) <B> Make sure you are prepared to begin the motor imagery experiment. </B>Press \"OK\" to begin the trials.\n",
    "\n",
    "7) After the experiment, press \"OK\" to close the program.\n",
    "\n",
    "\n",
    "Lab Recorder will generate the `EEG.xdf` file which contains the EEG and markers recording. It can be read with pyxdf.\n",
    "\n",
    "Python will generate `stimulus_vector.csv`, which contains the labels for each trial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2 - Data Preprocessing\n",
    "\n",
    "The `preprocess.py` script is responsible for cleaning the data.\n",
    "\n",
    "Currently, the pre-processing script uses low-pass, high-pass and notch filters to clean the data.\n",
    "\n",
    "The parameters for the filters are also part of the `params` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['preprocess']['filter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will output an `EEG_clean.csv` file, which contains the EEG data\n",
    "after the pre-processing. Additionally, the script exports a `.info` json file. The `.info` file\n",
    "contains all the info about the EEG stream. `extract_features.py` uses the info of the streaming.\n",
    "The output is automatically saved in the data directory.\n",
    "\n",
    "Let's plot the clean EEG data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "eeg_clean_path = '../data/noam/2/EEG_clean.csv'\n",
    "ch_names = ['C03', 'C04', 'P07', 'P089', 'O01', 'O02', 'F07', 'F08', 'F03', 'F04', 'T07', 'T08', 'P03']\n",
    "s_rate = 125\n",
    "\n",
    "# Create mne info & raw\n",
    "eeg_clean = np.genfromtxt(eeg_clean_path, delimiter=',', skip_header=1)[:, 1:]\n",
    "info = mne.create_info(ch_names, s_rate, verbose=False)\n",
    "raw_eeg_clean = mne.io.RawArray(eeg_clean.T, info, verbose=False)\n",
    "\n",
    "# Plot\n",
    "fig = raw_eeg_clean.plot_psd(picks=ch_names, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Data Segmentation\n",
    "\n",
    "In the `segment_data.py` script we split the data for each trial.\n",
    "The start and end of each trial is according to the markers streaming we created\n",
    "while recording the EEG. The script gets the subject folder from the config file\n",
    "(under `config['data']['subject_folder']`) and splits for trial each\n",
    "EEG record in each day.\n",
    "\n",
    "The output of MI3 script is a pickle file named `EEG_trials.pickle` which\n",
    "located in the corresponded day directory. The file is a list with ndarray\n",
    "where each ndarray is the corresponded EEG data of the trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "eeg_trials_path = '../data/noam/3/EEG_trials.pickle'\n",
    "eeg_trials = pickle.load(open(eeg_trials_path, 'rb'))\n",
    "\n",
    "print('Number of trials: {}\\nTrials dimensions: {}'.format(len(eeg_trials), eeg_trials[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a PSD plot of a specific trial look like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "eeg_trial = mne.io.RawArray(eeg_trials[103].T, info, verbose=False)\n",
    "fig = eeg_trial.plot_psd(picks=ch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Feature Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Train and Test a Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Experiment with ResNet Features\n",
    "\n",
    "As we was requested in the instructions we need to implement a different approach for one of\n",
    "the above-mentioned steps. We chose to re-implement features extraction step. Over the first time\n",
    "we used a classic approach in order to extract features from the EEG data to the ML model. These\n",
    "classic approach required a domain knowledge in the data - which channels are more important\n",
    "for MI classification, more common features for the classification problem and etc.\n",
    "In the re-implementation part we want to implement feature extraction method which not demand any domain-knowledge\n",
    "and to test the result of the model. We were constructed not to use any deep learning algorithm for\n",
    "the model step, but hey, we can definitely use one for the feature extraction step!\n",
    "\n",
    "We decided to use pre-trained Convolutional Neural Network (CNN) in order to extract\n",
    "features from each EEG trial. The CNN consist on first on convolutional layers and then on fully-connected layers.\n",
    "So, we used the pre-trained ResNet, which been trained on the 'imagenet' dataset, and use it\n",
    "where `include_top=False`, i.e., we used only the output of the convolutional layers.\n",
    "The ResNet input image size need to be at list `(32, 32)`. Since we got only 15 channels we needed to resize\n",
    "the EEG data in order to fit the ResNet input shape. The initial EEG resize is the first hyperparameter.\n",
    "\n",
    "Using a pooling layer we got from the ResNet a vector with 2048 features for each EEG trial.\n",
    "Then we used a PCA algorithm for dimensionality reduction. The number of components\n",
    "using the PCA is our second hyperparameter. Now we used it as our feature vector for the ML model.\n",
    "\n",
    "All the hyperparameters we used can be found in the `config.yaml` configuration\n",
    "file.\n",
    "\n",
    "Full of confidence we look through to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
